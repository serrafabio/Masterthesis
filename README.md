# Development of a resilient Reinforcement Learning-based decision algorithm for order scheduling

## Requirements

To run the simulation, the following software programs must be installed:

- [ ] [Matlab R2024a](https://www.mathworks.com/products/new_products/release2024a.html)
- [ ] [Reinforcement Learning Toolboxf for Matlab R2024a](https://www.mathworks.com/products/reinforcement-learning.html)

## Inputs

To run the simulation, the following inputs must be content in the working directory:

- inputData_Times.csv: Contains the machinery production and transportation times, as fixed inputs for each machinery to each product to be manufactured.
- inputData_Orders.csv: Contains the inputs about how each final product must be assembled and how it must look like.
- inputData-Storages.csv: Contains the maximum capacity of each storage
- inputData-StorageStatus.csv: Contains the inputs about the initial condition that the simulation must state with.
- inputData-Supplier.csv: Contains important information of each station, which has an internal storage, and how much time takes to delivery new pieces for each machinery storage.

All the inputs files must be .csv file to be imported by the matlab. For further explanation about the inputs, check the Master Thesis Document.

## Scripts

As described in the Master thesis Documentation, the algorithm runs two different methods, the traditional method and the Reinforcement Learning (RL) algorithm. Two run both algorithm two folders 
must be previously prepared to saving the output files. "time_trad" and "traditional" folders store the output files for the traditional method and the "results" and "time" store the files for the 
RL algorithm.
To run the main code of each method, you must do:
- Traditional Method: All functions concentrate in the script "TraditionalMethod.m"
- RL Method: The main code is the script "algo_simulation.m", which calls two Artificial Intelligence (AI) Methods to prepare the inputs before calling the simulation itself. Then the simulation is 
  called, and during the simulation there is AI application to control the storage during the simulation.

Additional scripts:
- prioritization.m: contains the RL algorithm to prioritize the order in a group of 4 according better descript in the documentation. This function works with productionfunction_2.m, which 
  contains the cost function as reward function.
- productionfunction_2.m: contains the cost function as reward function given to the prioritization.m.
- decideStage.m: function for the Petri Net Model Selection algorithm. Here the RL algorithm using the reward function as the cost function, which of the three possible petri net model it's make 
  sense to select, being the whole manufacture of the product or using available products in storage.
- productionfunction.m:  contains the cost function as reward function given to the decideStage.m.
- algo_simulation: this function is called to each product manufacture. It contains the simulation of the flow factory environment, and it contains the implementation of the 
  StorageDecisionFunction.m as the RL algorithm to check the storage status of the necessary phases.

## Outputs

The last script to run is the output analysis script. It enables to generate graphics about the analysis parameters of the outputs generated by the simulation of the methods. The script mentioned 
is named as "output_analysis.m". This script must adjust the path in file to run it correctly and select which scenario you want to examinate.
The outputs graphics that can be generated are:
- Makespan: Analysis the difference between the start and stop time of each phase, to analyse where the simulation has suffered more interferences.
- Mean Squared Error and Mean Absolute Error: Comparison errors analysis between the traditional and the RL methods.
- Computational Power: Analyse how much time the algorithm took to generate the results.

****

## Support
If further information or help, the e-mail in the AUTHORS are available for any contact.

## Roadmap

In the github, there are Issues for this project, where all the future improvements of this project are described.

## Authors and acknowledgment

> Developer: Serra Pereira, Fabio
> <br/>Contact: fabio.serrapereira@stud.tu-darmstadt.de

> Supervisor: Meldt, Leonie
> <br/>Contact: L.Meldt@PTW.TU-Darmstadt.de

## License

No license is required

## Project status

Version 1.0
